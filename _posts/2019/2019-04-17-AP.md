---
layout:     post
title:      AP聚类详解
subtitle:   Affinity Propagation
date:       2019-4-17
author:     maomaochen
header-img: img/post-bg-rwd.jpg
keywords_post:  "ML,聚类,AP算法"
catalog: true
tags:
    - ML
    - 聚类
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head> 
# Affinity Propagation聚类算法

思想：将所有样本看作是网络中的节点，通过网络中各条边的消息传递计算出各样本的聚类中心（中心是实际存在的样本）。聚类过程共有两种消息在节点中传递：

* **吸引度**（responsibility）
* **归属度**（availability）

AP算法在迭代过程中不断更新每一个点的吸引度和归属度，直到**产生$m$个高质量的Exemplar（类似质心）**，同时将其余点分配到相应类别中。

### 相关名词

> Exemplar：聚类中心
>
> Similarity：点$i$和$j$之间的相似度记为$s(i,j)$，是指$j$作为$i$的聚类中心的相似度。**一般用过欧氏距离的负表示，也可用其他的距离度量，保证值越大点与点之间的距离越近即可**，便于后续计算。
>
> **Preference**：点$i$的参考度称为$p(i)$或$s(i,i)$，是**点$i$作为聚类中心的参考度**，一般取$S$矩阵的中位值。当然**也可以为每一个点设置单独的参考度**，修改的结果体现在矩阵$S$的对角线元素上。**参考度变相的调节了聚类数目**。
>
> Responsibility：$r(i,k)$描述定$k$适合作为点$i$的聚类中心的程度，是从$i$到$k$的消息。
>
> Avaliability：$a(i,k)$描述$i$选择$k$作为聚类中心的合适程度，是从$k$到$i$的消息。
>
> **Dampling**：阻尼系数，控制算法的收敛，**避免震荡**。
>
> Preference和Dampling是需要手动调节的量，前者决定聚类数量，后者控制算法收敛。

### 算法流程

1）初始化，计算相似度矩阵$S$，$s(i,k)$是点$i$和$k$之间的欧氏距离的负（或其他越近相似度越大的度量）。

2）参考度$p$选取：**参考度表示数据被选作聚类中心的倾向性**，决定AP聚类输出的类别数量，在没有先验知识的情况下，所有数据点都是潜在的代表点，则$p$设为$S$中元素的中位值。

3）计算样本点间的吸引度$r$、归属度$a$（初始$R、A$矩阵为零矩阵）。**核心内容在于两个消息的反复传递**。

* 吸引度矩阵迭代如下：

  $$r_{t+1}(i, k)=s(i, k)-\max _{k^{\prime} \neq k}\left\{a_{t}\left(i, k^{\prime}\right)+s\left(i, k^{\prime}\right)\right\}$$

* 归属度矩阵迭代如下：

  $$\begin{array}{c}{a_{t+1}(i, k)=\min \left(0, r_{t}(k, k)+\sum_{i^{\prime} \notin\{i, k\}} \max \left\{0, r_{t}\left(i^{\prime}, k\right)\right\}\right), i \neq k} \\ {a_{t+1}(k, k)=\sum_{i^{\prime} \neq k} \max \left\{0, r_{t}\left(i^{\prime}, k\right)\right\}}\end{array}$$

4）更新$r、a$，下标$t$和$t+1$表示上一次和本次更新消息的最终结果，$\lambda$为阻尼系数（有博文标注其范围为$[0.5,1)​$?），用于调节算法收敛速度和迭代过程的稳定性。

$$\begin{aligned} r_{t+1}(i, k) & \leftarrow(1-\lambda) r_{t+1}(i, k)+\lambda r_{t}(i, k) \\ a_{t+1}(i, k) & \leftarrow(1-\lambda) a_{t+1}(i, k)+\lambda a_{t}(i, k) \end{aligned}$$

5) 确定聚类中心，确定样本的对应的中心：

$$k=\arg \max \{a(i, k) +r(i, k)\}$$

当$i=k$时，样本$i$是自己这个类的中心；当$i\neq j$时，则$k$是$i$的聚类中心。

另一种说法是找到所有决策矩阵主对角线元素${a(k,k)+r(k,k)}>0$的点，这些点全部都是聚类中心。

6） 迭代次数超过预先设定的值或聚类中心在若干次迭代中不发生变化时停止算法，确定类中心及类样本，否则返回步骤3）。




> 参考
>
> 1. [https://www.cnblogs.com/huadongw/p/4202492.html](https://www.cnblogs.com/huadongw/p/4202492.html)
> 2. [https://blog.csdn.net/zhouboke/article/details/80626962](https://blog.csdn.net/zhouboke/article/details/80626962)



<br>